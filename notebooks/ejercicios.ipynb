{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6808d6c",
   "metadata": {},
   "source": [
    "ğŸ¯ Nivel 1: BÃ¡sico (Entender el cÃ³digo)\n",
    "\n",
    "Ejercicio 1. 1: Explorar el Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e7512",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ“‹ OBJETIVO: Familiarizarse con los datos\n",
    "\n",
    "TAREAS:\n",
    "1. Carga el archivo failures_for_embeddings.csv\n",
    "2. Â¿CuÃ¡ntas startups hay?\n",
    "3. Â¿CuÃ¡ntos sectores Ãºnicos existen?\n",
    "4.  Â¿CuÃ¡l es el sector con mÃ¡s startups fallidas?\n",
    "5.  Muestra 5 ejemplos de startups del sector \"Tech\"\n",
    "\n",
    "ENTREGA: Notebook con respuestas y cÃ³digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c07d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d4604",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"data/gold/failures_for_embeddings.csv\")\n",
    "\n",
    "# 1. Â¿CuÃ¡ntas startups hay?\n",
    "print(f\"Total startups: {len(df)}\")\n",
    "# Respuesta: 409\n",
    "\n",
    "# 2. Â¿CuÃ¡ntos sectores Ãºnicos? \n",
    "print(f\"Sectores Ãºnicos: {df['sector'].nunique()}\")\n",
    "# Respuesta: 12 (aproximadamente)\n",
    "\n",
    "# 3. Â¿Sector con mÃ¡s startups fallidas?\n",
    "print(\"Sector mÃ¡s comÃºn:\")\n",
    "print(df['sector'].value_counts().head(1))\n",
    "# Respuesta: Probablemente \"Information\" o \"Tech\"\n",
    "\n",
    "# 4. DistribuciÃ³n completa de sectores\n",
    "print(\"\\nDistribuciÃ³n por sector:\")\n",
    "print(df['sector'].value_counts())\n",
    "\n",
    "# 5. 5 ejemplos del sector Tech\n",
    "print(\"\\n5 startups de Tech:\")\n",
    "tech_startups = df[df['sector']. str.contains('Tech|Information', case=False, na=False)]\n",
    "print(tech_startups[['name', 'sector', 'text']].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ded719",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Ejercicio 1.2: Entender los Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365939f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ“‹ OBJETIVO: Comprender quÃ© son los embeddings\n",
    "\n",
    "TAREAS:\n",
    "1. Carga el archivo embeddings. npy\n",
    "2. Â¿QuÃ© dimensiones tiene la matriz?\n",
    "3.  Â¿QuÃ© representa cada fila?\n",
    "4.  Â¿QuÃ© representa cada columna? \n",
    "5.  Muestra el embedding de la primera startup\n",
    "\n",
    "PREGUNTAS:\n",
    "- Â¿Por quÃ© son 384 dimensiones? \n",
    "- Â¿QuÃ© modelo generÃ³ estos embeddings? \n",
    "\n",
    "ENTREGA: Respuestas + cÃ³digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47809d2e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bef244",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar embeddings\n",
    "embeddings = np.load(\"data/gold/embeddings.npy\")\n",
    "df = pd.read_csv(\"data/gold/failures_for_embeddings.csv\")\n",
    "\n",
    "# 1. Dimensiones de la matriz\n",
    "print(f\"Shape: {embeddings.shape}\")\n",
    "# Respuesta: (409, 384)\n",
    "\n",
    "# 2. Â¿QuÃ© representa cada fila?\n",
    "print(f\"\\nCada fila = 1 startup\")\n",
    "print(f\"Total filas: {embeddings.shape[0]} startups\")\n",
    "\n",
    "# 3. Â¿QuÃ© representa cada columna? \n",
    "print(f\"\\nCada columna = 1 dimensiÃ³n del embedding\")\n",
    "print(f\"Total columnas: {embeddings.shape[1]} dimensiones\")\n",
    "\n",
    "# 4. Embedding de la primera startup\n",
    "print(f\"\\nPrimera startup: {df.iloc[0]['name']}\")\n",
    "print(f\"Embedding (primeros 10 valores): {embeddings[0][:10]}\")\n",
    "print(f\"Embedding (Ãºltimos 10 valores): {embeddings[0][-10:]}\")\n",
    "\n",
    "# 5. EstadÃ­sticas del embedding\n",
    "print(f\"\\nEstadÃ­sticas del primer embedding:\")\n",
    "print(f\"  Min: {embeddings[0].min():. 4f}\")\n",
    "print(f\"  Max: {embeddings[0].max():.4f}\")\n",
    "print(f\"  Media: {embeddings[0].mean():. 4f}\")\n",
    "print(f\"  Std: {embeddings[0].std():.4f}\")\n",
    "\n",
    "# RESPUESTAS A PREGUNTAS:\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESPUESTAS:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\"\"\n",
    "Â¿Por quÃ© 384 dimensiones? \n",
    "- Es la arquitectura del modelo all-MiniLM-L6-v2\n",
    "- Modelos mÃ¡s grandes tienen mÃ¡s dimensiones (768, 1024)\n",
    "- 384 es un buen balance entre calidad y velocidad\n",
    "\n",
    "Â¿QuÃ© modelo generÃ³ estos embeddings? \n",
    "- Sentence Transformers: all-MiniLM-L6-v2\n",
    "- Es un modelo pre-entrenado para generar embeddings de oraciones\n",
    "- Basado en BERT pero mÃ¡s pequeÃ±o y rÃ¡pido\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9a8b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Ejercicio 1.3: Cosine Similarity Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf6e53",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ“‹ OBJETIVO: Calcular similitud entre dos textos\n",
    "\n",
    "TAREAS:\n",
    "1.  Usa Sentence Transformers para generar embeddings de:\n",
    "   - \"App de delivery de comida\"\n",
    "   - \"Plataforma de entrega de alimentos\"\n",
    "   - \"Software de contabilidad\"\n",
    "   \n",
    "2. Calcula la similitud coseno entre los 3 pares\n",
    "3. Â¿CuÃ¡les son mÃ¡s similares?  Â¿Por quÃ©?\n",
    "\n",
    "ENTREGA: CÃ³digo + explicaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e5049",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c28ba2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Cargar modelo\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Textos a comparar\n",
    "textos = [\n",
    "    \"App de delivery de comida\",           # Texto 0\n",
    "    \"Plataforma de entrega de alimentos\",  # Texto 1\n",
    "    \"Software de contabilidad\"             # Texto 2\n",
    "]\n",
    "\n",
    "# Generar embeddings\n",
    "embeddings = model.encode(textos)\n",
    "print(f\"Shape de embeddings: {embeddings.shape}\")  # (3, 384)\n",
    "\n",
    "# Calcular similitud coseno entre todos los pares\n",
    "similitudes = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"\\nMatriz de similitud:\")\n",
    "print(\"=\"*50)\n",
    "for i, texto_i in enumerate(textos):\n",
    "    for j, texto_j in enumerate(textos):\n",
    "        print(f\"[{i}] vs [{j}]: {similitudes[i][j]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# InterpretaciÃ³n mÃ¡s clara\n",
    "print(\"\\nRESULTADOS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"'Delivery de comida' vs 'Entrega de alimentos': {similitudes[0][1]:.4f}\")\n",
    "print(f\"'Delivery de comida' vs 'Software contabilidad': {similitudes[0][2]:.4f}\")\n",
    "print(f\"'Entrega de alimentos' vs 'Software contabilidad': {similitudes[1][2]:.4f}\")\n",
    "\n",
    "print(\"\\nCONCLUSIÃ“N:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\"\"\n",
    "- Los textos 0 y 1 son MUY SIMILARES (~0.75-0.85)\n",
    "  Aunque usan palabras diferentes, significan lo mismo\n",
    "  \n",
    "- Los textos 0/1 vs 2 son MUY DIFERENTES (~0.15-0.25)\n",
    "  Son dominios completamente distintos\n",
    "\n",
    "- Esto demuestra que los embeddings capturan SIGNIFICADO,\n",
    "  no solo coincidencia de palabras\n",
    "\"\"\")\n",
    "\n",
    "# BONUS: Visualizar como heatmap\n",
    "import matplotlib. pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(similitudes, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Similitud')\n",
    "plt. xticks([0, 1, 2], ['Delivery', 'Entrega', 'Contabilidad'], rotation=45)\n",
    "plt.yticks([0, 1, 2], ['Delivery', 'Entrega', 'Contabilidad'])\n",
    "plt.title('Matriz de Similitud Coseno')\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.text(j, i, f'{similitudes[i][j]:. 2f}', ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('similitud_heatmap. png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7817c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ¯ Nivel 2: Intermedio (Modificar el cÃ³digo)\n",
    "\n",
    "Ejercicio 2. 1: Cambiar el Top-K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6d955",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ“‹ OBJETIVO: Modificar cuÃ¡ntos resultados devuelve la bÃºsqueda\n",
    "\n",
    "TAREAS:\n",
    "1. Modifica la funciÃ³n buscar_startups_similares()\n",
    "2. AÃ±ade un parÃ¡metro top_k con valor por defecto 3\n",
    "3. Prueba con top_k = 1, 3, 5, 10\n",
    "4.  Â¿CÃ³mo afecta al resultado?\n",
    "\n",
    "BONUS: AÃ±ade un slider en Streamlit para que el usuario elija\n",
    "\n",
    "ENTREGA: CÃ³digo modificado + observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387e573",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed21e82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics. pairwise import cosine_similarity\n",
    "\n",
    "# Cargar datos\n",
    "df = pd. read_csv(\"data/gold/failures_for_embeddings. csv\")\n",
    "embeddings = np. load(\"data/gold/embeddings.npy\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def buscar_startups_similares(descripcion, top_k=3):\n",
    "    \"\"\"\n",
    "    Busca las startups mÃ¡s similares a la descripciÃ³n dada. \n",
    "    \n",
    "    Args:\n",
    "        descripcion: Texto describiendo la startup\n",
    "        top_k: NÃºmero de resultados a devolver (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con las startups mÃ¡s similares\n",
    "    \"\"\"\n",
    "    # 1. Generar embedding del usuario\n",
    "    embedding_usuario = model.encode([descripcion])\n",
    "    \n",
    "    # 2. Calcular similitud con todos\n",
    "    similitudes = cosine_similarity(embedding_usuario, embeddings)[0]\n",
    "    \n",
    "    # 3.  Obtener Ã­ndices de los top_k mÃ¡s similares\n",
    "    top_indices = np. argsort(similitudes)[-top_k:][::-1]\n",
    "    \n",
    "    # 4.  Crear dataframe con resultados\n",
    "    resultados = df.iloc[top_indices]. copy()\n",
    "    resultados['similitud'] = similitudes[top_indices]\n",
    "    \n",
    "    return resultados[['name', 'sector', 'text', 'similitud']]\n",
    "\n",
    "\n",
    "# PRUEBAS con diferentes top_k\n",
    "query = \"food delivery app with high costs\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for k in [1, 3, 5, 10]:\n",
    "    print(f\"\\n--- TOP {k} ---\")\n",
    "    resultados = buscar_startups_similares(query, top_k=k)\n",
    "    for idx, row in resultados.iterrows():\n",
    "        print(f\"  {row['name']:20} | Sim: {row['similitud']:.4f} | {row['sector']}\")\n",
    "\n",
    "# OBSERVACIONES\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OBSERVACIONES:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "- top_k=1: Solo el mÃ¡s similar, Ãºtil para respuestas rÃ¡pidas\n",
    "- top_k=3: Balance entre diversidad y relevancia (recomendado)\n",
    "- top_k=5: MÃ¡s contexto para el LLM\n",
    "- top_k=10: Demasiado, puede incluir resultados poco relevantes\n",
    "\n",
    "La similitud baja conforme aumenta K:\n",
    "- Top 1: ~0.40\n",
    "- Top 3: ~0.35-0.40\n",
    "- Top 5: ~0.30-0.40\n",
    "- Top 10: ~0.25-0.40\n",
    "\n",
    "RECOMENDACIÃ“N: top_k=3 o top_k=5 para RAG\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# BONUS: Slider en Streamlit\n",
    "\"\"\"\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Startup Death Oracle\")\n",
    "\n",
    "descripcion = st.text_area(\"Describe tu startup:\")\n",
    "\n",
    "# Slider para top_k\n",
    "top_k = st.slider(\"Â¿CuÃ¡ntas startups similares buscar?\", 1, 10, 3)\n",
    "\n",
    "if st.button(\"Predecir\"):\n",
    "    resultados = buscar_startups_similares(descripcion, top_k=top_k)\n",
    "    st.dataframe(resultados)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec6ed0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Ejercicio 2.2: AÃ±adir Filtro por Sector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d9a20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ“‹ OBJETIVO: Filtrar resultados por sector\n",
    "\n",
    "TAREAS:\n",
    "1. Modifica la bÃºsqueda para aceptar un parÃ¡metro sector\n",
    "2. Si sector != None, solo buscar en ese sector\n",
    "3.  Prueba: buscar \"delivery app\" solo en sector \"Food\"\n",
    "\n",
    "PREGUNTAS:\n",
    "- Â¿Cambian los resultados? \n",
    "- Â¿CuÃ¡ndo serÃ­a Ãºtil este filtro? \n",
    "\n",
    "ENTREGA: CÃ³digo + pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d51686",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78da678",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn. metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"data/gold/failures_for_embeddings.csv\")\n",
    "embeddings = np.load(\"data/gold/embeddings.npy\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def buscar_startups_similares(descripcion, top_k=3, sector=None):\n",
    "    \"\"\"\n",
    "    Busca startups similares, opcionalmente filtradas por sector. \n",
    "    \n",
    "    Args:\n",
    "        descripcion: Texto describiendo la startup\n",
    "        top_k: NÃºmero de resultados\n",
    "        sector: Filtrar por sector (None = todos)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con resultados\n",
    "    \"\"\"\n",
    "    # 1.  Generar embedding del usuario\n",
    "    embedding_usuario = model.encode([descripcion])\n",
    "    \n",
    "    # 2. Filtrar por sector si se especifica\n",
    "    if sector:\n",
    "        # Obtener Ã­ndices del sector\n",
    "        mask = df['sector']. str.contains(sector, case=False, na=False)\n",
    "        df_filtrado = df[mask]. copy()\n",
    "        embeddings_filtrados = embeddings[mask]\n",
    "        \n",
    "        if len(df_filtrado) == 0:\n",
    "            print(f\"No hay startups en el sector '{sector}'\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        df_filtrado = df.copy()\n",
    "        embeddings_filtrados = embeddings\n",
    "    \n",
    "    # 3. Calcular similitud\n",
    "    similitudes = cosine_similarity(embedding_usuario, embeddings_filtrados)[0]\n",
    "    \n",
    "    # 4.  Obtener top_k (o menos si no hay suficientes)\n",
    "    k = min(top_k, len(df_filtrado))\n",
    "    top_indices = np.argsort(similitudes)[-k:][::-1]\n",
    "    \n",
    "    # 5.  Crear resultados\n",
    "    resultados = df_filtrado.iloc[top_indices].copy()\n",
    "    resultados['similitud'] = similitudes[top_indices]\n",
    "    \n",
    "    return resultados[['name', 'sector', 'text', 'similitud']]\n",
    "\n",
    "\n",
    "# PRUEBAS\n",
    "query = \"food delivery app\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sin filtro\n",
    "print(\"\\n--- SIN FILTRO (todos los sectores) ---\")\n",
    "resultados = buscar_startups_similares(query, top_k=5)\n",
    "for idx, row in resultados. iterrows():\n",
    "    print(f\"  {row['name']:20} | {row['sector']:30} | {row['similitud']:.4f}\")\n",
    "\n",
    "# Con filtro Food\n",
    "print(\"\\n--- FILTRO: Food ---\")\n",
    "resultados = buscar_startups_similares(query, top_k=5, sector=\"Food\")\n",
    "for idx, row in resultados.iterrows():\n",
    "    print(f\"  {row['name']:20} | {row['sector']:30} | {row['similitud']:.4f}\")\n",
    "\n",
    "# Con filtro Health\n",
    "print(\"\\n--- FILTRO: Health ---\")\n",
    "resultados = buscar_startups_similares(query, top_k=5, sector=\"Health\")\n",
    "for idx, row in resultados.iterrows():\n",
    "    print(f\"  {row['name']:20} | {row['sector']:30} | {row['similitud']:.4f}\")\n",
    "\n",
    "# Listar sectores disponibles\n",
    "print(\"\\n--- SECTORES DISPONIBLES ---\")\n",
    "print(df['sector'].value_counts())\n",
    "\n",
    "# OBSERVACIONES\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OBSERVACIONES:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Â¿Cambian los resultados? \n",
    "- SÃ, significativamente\n",
    "- Sin filtro: mezcla sectores (Food, Tech, Health)\n",
    "- Con filtro Food: solo startups de comida\n",
    "- Con filtro Health: busca \"delivery\" en contexto de salud\n",
    "\n",
    "Â¿CuÃ¡ndo es Ãºtil este filtro?\n",
    "- Cuando el usuario quiere compararse con su industria\n",
    "- Para anÃ¡lisis especÃ­fico de un sector\n",
    "- Para evitar comparaciones irrelevantes\n",
    "  (ej: una startup de food no deberÃ­a compararse con fintech)\n",
    "\n",
    "CUIDADO:\n",
    "- Si el sector tiene pocas startups, los resultados serÃ¡n pobres\n",
    "- Algunos sectores tienen <10 startups\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ec719",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Ejercicio 2. 3: Nuevo Modelo de Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e90b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ“‹ OBJETIVO: Comparar diferentes modelos de embeddings\n",
    "\n",
    "TAREAS:\n",
    "1.  Genera embeddings con estos 3 modelos:\n",
    "   - all-MiniLM-L6-v2 (actual)\n",
    "   - all-mpnet-base-v2\n",
    "   - paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "2. Para cada modelo:\n",
    "   - Â¿CuÃ¡ntas dimensiones tiene? \n",
    "   - Â¿CuÃ¡nto tarda en generar 409 embeddings? \n",
    "   \n",
    "3. Busca \"food delivery app\" con cada modelo\n",
    "4. Â¿Cambian los resultados?  Â¿CuÃ¡l es mejor?\n",
    "\n",
    "ENTREGA: Tabla comparativa + conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5fe16",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0cb2c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"data/gold/failures_for_embeddings.csv\")\n",
    "textos = df['text'].tolist()\n",
    "\n",
    "# Modelos a comparar\n",
    "modelos = [\n",
    "    'all-MiniLM-L6-v2',                    # Actual (rÃ¡pido, ligero)\n",
    "    'all-mpnet-base-v2',                   # Mejor calidad, mÃ¡s lento\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2'  # MultilingÃ¼e\n",
    "]\n",
    "\n",
    "resultados_modelos = {}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPARACIÃ“N DE MODELOS DE EMBEDDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for nombre_modelo in modelos:\n",
    "    print(f\"\\n--- Cargando: {nombre_modelo} ---\")\n",
    "    \n",
    "    # Cargar modelo\n",
    "    model = SentenceTransformer(nombre_modelo)\n",
    "    \n",
    "    # Medir tiempo de generaciÃ³n\n",
    "    inicio = time.time()\n",
    "    embeddings = model.encode(textos, show_progress_bar=True)\n",
    "    tiempo = time.time() - inicio\n",
    "    \n",
    "    # Guardar resultados\n",
    "    resultados_modelos[nombre_modelo] = {\n",
    "        'embeddings': embeddings,\n",
    "        'dimensiones': embeddings.shape[1],\n",
    "        'tiempo': tiempo,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"  Dimensiones: {embeddings.shape[1]}\")\n",
    "    print(f\"  Tiempo: {tiempo:.2f} segundos\")\n",
    "    print(f\"  TamaÃ±o: {embeddings.nbytes / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "\n",
    "# TABLA COMPARATIVA\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLA COMPARATIVA\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Modelo':<45} | {'Dims':>6} | {'Tiempo':>8} | {'MB':>6}\")\n",
    "print(\"-\"*70)\n",
    "for nombre, datos in resultados_modelos.items():\n",
    "    mb = datos['embeddings'].nbytes / 1024 / 1024\n",
    "    print(f\"{nombre:<45} | {datos['dimensiones']:>6} | {datos['tiempo']:>6.2f}s | {mb:>5.2f}\")\n",
    "\n",
    "\n",
    "# COMPARAR BÃšSQUEDA\n",
    "query = \"food delivery app with high costs\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"BÃšSQUEDA: '{query}'\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for nombre_modelo, datos in resultados_modelos.items():\n",
    "    print(f\"\\n--- {nombre_modelo} ---\")\n",
    "    \n",
    "    # Generar embedding de la query\n",
    "    query_embedding = datos['model'].encode([query])\n",
    "    \n",
    "    # Calcular similitud\n",
    "    similitudes = cosine_similarity(query_embedding, datos['embeddings'])[0]\n",
    "    \n",
    "    # Top 3\n",
    "    top_indices = np.argsort(similitudes)[-3:][::-1]\n",
    "    \n",
    "    for i, idx in enumerate(top_indices):\n",
    "        print(f\"  {i+1}. {df.iloc[idx]['name']:20} | Sim: {similitudes[idx]:.4f}\")\n",
    "\n",
    "\n",
    "# CONCLUSIONES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSIONES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ MODELO                              â”‚ PROS              â”‚ CONTRAS   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ all-MiniLM-L6-v2                    â”‚ RÃ¡pido, ligero    â”‚ Menos     â”‚\n",
    "â”‚ (ACTUAL)                            â”‚ 384 dims          â”‚ preciso   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ all-mpnet-base-v2                   â”‚ Mejor calidad     â”‚ MÃ¡s lento â”‚\n",
    "â”‚                                     â”‚ 768 dims          â”‚ MÃ¡s RAM   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ paraphrase-multilingual-MiniLM-L12  â”‚ MultilingÃ¼e       â”‚ Menos     â”‚\n",
    "â”‚                                     â”‚ EspaÃ±ol nativo    â”‚ preciso   â”‚\n",
    "â”‚                                     â”‚                   â”‚ en inglÃ©s â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "RECOMENDACIONES:\n",
    "- Prototipo rÃ¡pido: all-MiniLM-L6-v2 âœ“ (actual)\n",
    "- Mejor calidad: all-mpnet-base-v2\n",
    "- Datos en espaÃ±ol: paraphrase-multilingual-MiniLM-L12-v2\n",
    "- ProducciÃ³n con mucho trÃ¡fico: all-MiniLM-L6-v2\n",
    "\n",
    "Â¿Cambian los resultados? \n",
    "- SÃ­, ligeramente\n",
    "- Los top-1 suelen coincidir\n",
    "- Los top-3 pueden variar en orden\n",
    "- mpnet tiende a dar scores mÃ¡s altos\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77db19",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Ejercicio 2.4: Implementar ChromaDB desde Cero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e18a1d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ“‹ OBJETIVO: Crear tu propia colecciÃ³n en ChromaDB\n",
    "\n",
    "TAREAS:\n",
    "1. Instala chromadb: pip install chromadb\n",
    "2. Crea una colecciÃ³n llamada \"mis_startups\"\n",
    "3. AÃ±ade las 409 startups con sus metadatos\n",
    "4.  Implementa funciÃ³n buscar_con_mi_chroma()\n",
    "5.  Compara resultados con Cosine manual\n",
    "\n",
    "ENTREGA: CÃ³digo completo funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89011b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fa96c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb. utils import embedding_functions\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"data/gold/failures_for_embeddings.csv\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"IMPLEMENTACIÃ“N DE CHROMADB\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Crear cliente de ChromaDB\n",
    "print(\"\\n1.  Creando cliente ChromaDB...\")\n",
    "client = chromadb. Client()  # En memoria\n",
    "# client = chromadb.PersistentClient(path=\"./chroma_db\")  # Persistente\n",
    "\n",
    "# 2. Configurar funciÃ³n de embeddings\n",
    "print(\"2. Configurando embedding function...\")\n",
    "sentence_transformer_ef = embedding_functions. SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 3. Crear colecciÃ³n (eliminar si existe)\n",
    "print(\"3.  Creando colecciÃ³n 'mis_startups'...\")\n",
    "try:\n",
    "    client.delete_collection(\"mis_startups\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name=\"mis_startups\",\n",
    "    embedding_function=sentence_transformer_ef,\n",
    "    metadata={\"description\": \"Startups fallidas para RAG\"}\n",
    ")\n",
    "\n",
    "# 4.  Preparar datos para insertar\n",
    "print(\"4.  Preparando datos...\")\n",
    "documents = df['text']. tolist()\n",
    "metadatas = [\n",
    "    {\n",
    "        \"nombre\": row['name'],\n",
    "        \"sector\": row['sector'] if pd.notna(row['sector']) else \"Unknown\"\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "ids = [f\"startup_{i}\" for i in range(len(df))]\n",
    "\n",
    "# 5. AÃ±adir documentos a la colecciÃ³n\n",
    "print(\"5.  AÃ±adiendo documentos a ChromaDB...\")\n",
    "# AÃ±adir en batches para evitar problemas de memoria\n",
    "batch_size = 100\n",
    "for i in range(0, len(documents), batch_size):\n",
    "    end = min(i + batch_size, len(documents))\n",
    "    collection.add(\n",
    "        documents=documents[i:end],\n",
    "        metadatas=metadatas[i:end],\n",
    "        ids=ids[i:end]\n",
    "    )\n",
    "    print(f\"   AÃ±adidos {end}/{len(documents)} documentos\")\n",
    "\n",
    "print(f\"\\nâœ“ ColecciÃ³n creada con {collection.count()} documentos\")\n",
    "\n",
    "\n",
    "# 6.  FunciÃ³n de bÃºsqueda con ChromaDB\n",
    "def buscar_con_mi_chroma(query, n_results=3, sector=None):\n",
    "    \"\"\"\n",
    "    Busca startups similares usando ChromaDB. \n",
    "    \n",
    "    Args:\n",
    "        query: Texto de bÃºsqueda\n",
    "        n_results: NÃºmero de resultados\n",
    "        sector: Filtrar por sector (opcional)\n",
    "    \n",
    "    Returns:\n",
    "        dict con resultados\n",
    "    \"\"\"\n",
    "    # Preparar filtro si hay sector\n",
    "    where_filter = None\n",
    "    if sector:\n",
    "        where_filter = {\"sector\": {\"$contains\": sector}}\n",
    "    \n",
    "    # Buscar\n",
    "    resultados = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results,\n",
    "        where=where_filter,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "\n",
    "# 7.  PRUEBAS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRUEBAS DE BÃšSQUEDA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prueba 1: BÃºsqueda simple\n",
    "query = \"food delivery app with high costs\"\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "resultados = buscar_con_mi_chroma(query, n_results=3)\n",
    "\n",
    "for i in range(len(resultados['ids'][0])):\n",
    "    nombre = resultados['metadatas'][0][i]['nombre']\n",
    "    sector = resultados['metadatas'][0][i]['sector']\n",
    "    distancia = resultados['distances'][0][i]\n",
    "    similitud = 1 - distancia  # ChromaDB usa distancia, no similitud\n",
    "    print(f\"{i+1}.  {nombre:20} | {sector:25} | Sim: {similitud:. 4f}\")\n",
    "\n",
    "\n",
    "# Prueba 2: Con filtro de sector\n",
    "print(f\"\\nQuery con filtro sector='Food':\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "resultados = buscar_con_mi_chroma(query, n_results=3, sector=\"Food\")\n",
    "\n",
    "if resultados['ids'][0]:\n",
    "    for i in range(len(resultados['ids'][0])):\n",
    "        nombre = resultados['metadatas'][0][i]['nombre']\n",
    "        sector = resultados['metadatas'][0][i]['sector']\n",
    "        distancia = resultados['distances'][0][i]\n",
    "        similitud = 1 - distancia\n",
    "        print(f\"{i+1}. {nombre:20} | {sector:25} | Sim: {similitud:.4f}\")\n",
    "else:\n",
    "    print(\"No se encontraron resultados con ese filtro\")\n",
    "\n",
    "\n",
    "# 8. COMPARACIÃ“N CON MÃ‰TODO MANUAL\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARACIÃ“N: ChromaDB vs Cosine Manual\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics. pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Cargar para mÃ©todo manual\n",
    "embeddings_np = np.load(\"data/gold/embeddings.npy\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Medir tiempo ChromaDB\n",
    "inicio = time.time()\n",
    "for _ in range(10):\n",
    "    buscar_con_mi_chroma(query, n_results=3)\n",
    "tiempo_chroma = (time.time() - inicio) / 10\n",
    "\n",
    "# Medir tiempo Cosine manual\n",
    "inicio = time. time()\n",
    "for _ in range(10):\n",
    "    query_emb = model.encode([query])\n",
    "    sims = cosine_similarity(query_emb, embeddings_np)\n",
    "    top_3 = np.argsort(sims[0])[-3:][::-1]\n",
    "tiempo_manual = (time.time() - inicio) / 10\n",
    "\n",
    "print(f\"ChromaDB: {tiempo_chroma*1000:.2f} ms por bÃºsqueda\")\n",
    "print(f\"Cosine Manual: {tiempo_manual*1000:.2f} ms por bÃºsqueda\")\n",
    "print(f\"ChromaDB es {tiempo_manual/tiempo_chroma:. 1f}x mÃ¡s rÃ¡pido\")\n",
    "\n",
    "print(\"\"\"\n",
    "NOTA: Con 409 documentos la diferencia es pequeÃ±a. \n",
    "Con 1,000,000 documentos, ChromaDB serÃ­a ~1000x mÃ¡s rÃ¡pido.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
